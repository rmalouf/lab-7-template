{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fuzzy-layer",
   "metadata": {},
   "source": [
    "# LAB 7: Error analysis\n",
    "\n",
    "Objectives\n",
    "* Construct a  linear text classifier using SGDClassifier\n",
    "* Evaluate its performance and categorize the errors that it makes\n",
    "* Eaxmine model's coefficients and decision function values\n",
    "* Interpret model results using LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-delight",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\n",
    "    \"s3://ling583/lab7-train.parquet\", storage_options={\"anon\": True}\n",
    ")\n",
    "test = pd.read_parquet(\"s3://ling583/lab7-test.parquet\", storage_options={\"anon\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    exclude=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\", \"attribute_ruler\"],\n",
    ")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    return [t.norm_ for t in doc if not (t.is_space or t.is_punct or t.like_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool() as p:\n",
    "    train[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(train[\"text\"]), chunksize=100))\n",
    "    test[\"tokens\"] = pd.Series(p.imap(tokenize, tqdm(test[\"text\"]), chunksize=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-lesbian",
   "metadata": {},
   "source": [
    "The labels are: GPOL = domestic politics, GSPO = sports, GVIO = war/civil war, GJOB = labor issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"topics\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-champagne",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = make_pipeline(CountVectorizer(analyzer=identity), SGDClassifier())\n",
    "baseline.fit(train[\"tokens\"], train[\"topics\"])\n",
    "base_predicted = baseline.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], base_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-machine",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Hyperparameter search\n",
    "\n",
    "Find an optimal set of hyperparameters for a Tfidf+SGDClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from logger import log_search\n",
    "from scipy.stats.distributions import loguniform, randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:xxxxx\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"lab-7\")\n",
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity), TfidfTransformer(), SGDClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    sgd,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 20),\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"tfidftransformer__use_idf\": [True, False],\n",
    "        \"sgdclassifier__alpha\": loguniform(1e-6, 1e-2),\n",
    "    },\n",
    "    n_iter=50,\n",
    "    scoring=\"f1_macro\",\n",
    ")\n",
    "search.fit(train[\"tokens\"], train[\"topics\"])\n",
    "log_search(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-zealand",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compare optimized model to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(analyzer=identity, min_df=x, max_df=x),\n",
    "    TfidfTransformer(use_idf=True),\n",
    "    SGDClassifier(alpha=x),\n",
    ")\n",
    "sgd.fit(train[\"tokens\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"tokens\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_f1 = f1_score(test[\"topics\"], base_predicted, average=\"macro\")\n",
    "sgd_f1 = f1_score(test[\"topics\"], predicted, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_f1, sgd_f1, sgd_f1 - base_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "(sgd_f1 - base_f1) / (1 - base_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom_test, wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (predicted == test[\"topics\"]).astype(int) - (\n",
    "    base_predicted == test[\"topics\"]\n",
    ").astype(int)\n",
    "sum(diff == 1), sum(diff == -1), sum(diff == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "binom_test([sum(diff == 1), sum(diff == -1)], alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcoxon(diff, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-confidence",
   "metadata": {},
   "source": [
    "**TO DO:** Summarize your results: how much better is the optimized model? Is it significantly better than the baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-mills",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = make_pipeline(\n",
    "    CountVectorizer(preprocessor=identity, tokenizer=tokenize, min_df=x, max_df=x),\n",
    "    TfidfTransformer(use_idf=True),\n",
    "    SGDClassifier(alpha=x),\n",
    ")\n",
    "sgd.fit(train[\"text\"], train[\"topics\"])\n",
    "predicted = sgd.predict(test[\"text\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudpickle.dump(sgd, open(\"sgd.model\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
