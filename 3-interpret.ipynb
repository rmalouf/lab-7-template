{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-aberdeen",
   "metadata": {},
   "source": [
    "# LAB 7: Error analysis\n",
    "\n",
    "Objectives\n",
    "* Construct a  linear text classifier using SGDClassifier\n",
    "* Evaluate its performance and categorize the errors that it makes\n",
    "* Eaxmine model's coefficients and decision function values\n",
    "* Interpret model results using LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-superior",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"s3://ling583/lab7-train.parquet\", storage_options={\"anon\":True})\n",
    "test = pd.read_parquet(\"s3://ling583/lab7-test.parquet\", storage_options={\"anon\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "from sklearn.metrics import classification_report, f1_score, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = cloudpickle.load(open(\"sgd.model\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = sgd.predict(test[\"text\"])\n",
    "print(classification_report(test[\"topics\"], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-bridal",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Decision function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sgd.named_steps['sgdclassifier'].classes_\n",
    "scores = sgd.decision_function(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['topics'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest = scores.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['topics'].iloc[?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'].iloc[?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-smile",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['topics'].iloc[?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'].iloc[?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.sort(axis=1)\n",
    "scores[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = scores[:,3]-scores[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin.max(), margin.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test[\"topics\"][margin > 5], predicted[margin > 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.linspace(-2, 3, 50)\n",
    "x = [100*(1-sum(margin > t)/len(margin)) for t in thresh]\n",
    "y = [f1_score(test[\"topics\"][margin > t], predicted[margin > t], average=\"macro\") for t in thresh]\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('% Unknowns')\n",
    "plt.ylabel('F1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test[\"topics\"][margin > 1.75], predicted[margin > 1.75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-decimal",
   "metadata": {},
   "source": [
    "**TO DO:** Summarize your results for this section. What could we do if we wanted to make label as many examples as possible while still keeping F1 above 0.99?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-queue",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = sgd.named_steps['sgdclassifier'].coef_\n",
    "labels, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sgd.named_steps['countvectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[0,:].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[0,13100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[13100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = np.argsort(coef, axis=1)\n",
    "for i, label in enumerate(labels):\n",
    "    print(label)\n",
    "    for j in concat([range(-1, -11, -1), range(10, 0, -1)]):\n",
    "        print(f'  {vocab[ranked[i,j]]:15s} {coef[i, ranked[i,j]]:6.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kwic import kwic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic('newsroom', train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic('zaire', train['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-dealer",
   "metadata": {},
   "source": [
    "**TO DO:** What can you conclude about the model from looking at the coefficients? Is there evidence of overfitting? How could we improve the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-nursing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
